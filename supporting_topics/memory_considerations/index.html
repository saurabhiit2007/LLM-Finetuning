
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="A technical reference for LoRA, QLoRA, and other fine-tuning techniques.">
      
      
        <meta name="author" content="Saurabh Goyal">
      
      
      
        <link rel="prev" href="../fsdp_deepspeed/">
      
      
        <link rel="next" href="../paged_adam/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.23">
    
    
      
        <title>Memory Consideration - Fine-Tuning Methods Documentation</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.84d31ad4.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7CJetBrains+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Inter";--md-code-font:"JetBrains Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="blue" data-md-color-accent="deep-purple">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#1-gpu-and-cpu-memory-and-transfer-rates" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Fine-Tuning Methods Documentation" class="md-header__button md-logo" aria-label="Fine-Tuning Methods Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Fine-Tuning Methods Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Memory Consideration
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="blue" data-md-color-accent="deep-purple"  aria-hidden="true"  type="radio" name="__palette" id="__palette_0">
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="blue" data-md-color-accent="lime"  aria-hidden="true"  type="radio" name="__palette" id="__palette_1">
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/saurabhiit2007/LLM-Finetuning" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Fine-Tuning Methods Documentation" class="md-nav__button md-logo" aria-label="Fine-Tuning Methods Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Fine-Tuning Methods Documentation
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/saurabhiit2007/LLM-Finetuning" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    PEFT Techniques
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            PEFT Techniques
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../finetuning_techniques/prefix_tuning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Prefix Tuning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../finetuning_techniques/lora/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    LoRA
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../finetuning_techniques/qlora/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    QLoRA
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Supporting Topics
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Supporting Topics
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../4bit_normal_float/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4-bit NormalFloat (NF4)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blockwise_kbit_quantization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Block-wise k-bit Quantization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../accelerate/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Accelerate Framework
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bp16/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    BP16
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../flash_attention/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Flash Attention
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../decoding_strategies/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Decoding Strategies
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../speculative_decoding/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Speculative Decoding & Medusa
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../kv_caching/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    KV Caching
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vllm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    vLLM
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fsdp_deepspeed/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    FSDP & Deep Speed
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Memory Consideration
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Memory Consideration
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-gpu-and-cpu-memory-and-transfer-rates" class="md-nav__link">
    <span class="md-ellipsis">
      1. GPU and CPU Memory and Transfer Rates
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. GPU and CPU Memory and Transfer Rates">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-gpu-memory" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 GPU Memory
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12-cpu-memory" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 CPU Memory
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13-gpu-to-cpu-transfer-rates" class="md-nav__link">
    <span class="md-ellipsis">
      1.3 GPU to CPU Transfer Rates
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-bandwidth-latency-and-compute" class="md-nav__link">
    <span class="md-ellipsis">
      2. Bandwidth, Latency, and Compute
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. Bandwidth, Latency, and Compute">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-bandwidth" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 Bandwidth
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-latency" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 Latency
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23-compute" class="md-nav__link">
    <span class="md-ellipsis">
      2.3 Compute
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#24-compute-vs-memory-bound-regimes" class="md-nav__link">
    <span class="md-ellipsis">
      2.4 Compute vs Memory Bound Regimes
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-training-considerations-for-a-7b-model-on-a-single-a100" class="md-nav__link">
    <span class="md-ellipsis">
      3. Training Considerations for a 7B Model on a Single A100
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Training Considerations for a 7B Model on a Single A100">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-memory-components-during-training" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 Memory Components During Training
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.1 Memory Components During Training">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameter-definitions" class="md-nav__link">
    <span class="md-ellipsis">
      Parameter Definitions
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#311-model-weights" class="md-nav__link">
    <span class="md-ellipsis">
      3.1.1 Model Weights
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#312-gradients" class="md-nav__link">
    <span class="md-ellipsis">
      3.1.2 Gradients
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#313-optimizer-states-adam-or-adamw" class="md-nav__link">
    <span class="md-ellipsis">
      3.1.3 Optimizer States (Adam or AdamW)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#314-activations" class="md-nav__link">
    <span class="md-ellipsis">
      3.1.4 Activations
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#315-total-training-memory" class="md-nav__link">
    <span class="md-ellipsis">
      3.1.5 Total Training Memory
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-techniques-that-enable-feasible-training" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 Techniques That Enable Feasible Training
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-cpu-offloading" class="md-nav__link">
    <span class="md-ellipsis">
      3.3 CPU Offloading
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-memory-differences-between-training-and-inference" class="md-nav__link">
    <span class="md-ellipsis">
      4. Memory Differences Between Training and Inference
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. Memory Differences Between Training and Inference">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41-training-memory-profile" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 Training Memory Profile
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42-inference-memory-profile" class="md-nav__link">
    <span class="md-ellipsis">
      4.2 Inference Memory Profile
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#43-quantitative-difference" class="md-nav__link">
    <span class="md-ellipsis">
      4.3 Quantitative Difference
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-kv-cache-memory-usage" class="md-nav__link">
    <span class="md-ellipsis">
      5. KV Cache Memory Usage
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5. KV Cache Memory Usage">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#51-what-is-the-kv-cache" class="md-nav__link">
    <span class="md-ellipsis">
      5.1 What Is the KV Cache
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#52-which-memory-does-kv-cache-use" class="md-nav__link">
    <span class="md-ellipsis">
      5.2 Which Memory Does KV Cache Use
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#53-kv-cache-memory-scaling" class="md-nav__link">
    <span class="md-ellipsis">
      5.3 KV Cache Memory Scaling
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-summary" class="md-nav__link">
    <span class="md-ellipsis">
      6. Summary
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../paged_adam/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Paged Adam Optimizer
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Training Pipeline
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Training Pipeline
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../training_techniques/foundation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Foundation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_2" >
        
          
          <label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Pre-Training
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2">
            <span class="md-nav__icon md-icon"></span>
            Pre-Training
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../training_techniques/pre_training/pre_training/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Pre-Training
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../training_techniques/pre_training/byte_pair_encoding/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Byte Pair Encoding
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../training_techniques/pre_training/mixture_of_experts/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Mixture of Experts (MoE)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../training_techniques/pre_training/RoPE/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    RoPe
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../training_techniques/pre_training/sentence_piece_unigram/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Sentence Piece Unigram
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../training_techniques/pre_training/advanced_transformer_components_and_layers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Advanced Transformer Components & Layers
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../training_techniques/training_optimization_and_stability/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Training Optimization and Stability
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../training_techniques/distributed_training_systems/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Distributed Training Systems
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_5" >
        
          
          <label class="md-nav__link" for="__nav_4_5" id="__nav_4_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Post-Training
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_5">
            <span class="md-nav__icon md-icon"></span>
            Post-Training
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../training_techniques/post_training/sft/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Supervised Fine-Tuning (SFT)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../training_techniques/system2.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Reasoning & Test-Time Compute (System 2)
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_6" >
        
          
          <label class="md-nav__link" for="__nav_4_6" id="__nav_4_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Mid-Training
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_6">
            <span class="md-nav__icon md-icon"></span>
            Mid-Training
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../training_techniques/mid_training/mid_training/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Mid Training Fundamentals
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../training_techniques/thinking_llms/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    LLM Reasoning & Thinking Models
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../references/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    References
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-gpu-and-cpu-memory-and-transfer-rates" class="md-nav__link">
    <span class="md-ellipsis">
      1. GPU and CPU Memory and Transfer Rates
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. GPU and CPU Memory and Transfer Rates">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-gpu-memory" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 GPU Memory
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12-cpu-memory" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 CPU Memory
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13-gpu-to-cpu-transfer-rates" class="md-nav__link">
    <span class="md-ellipsis">
      1.3 GPU to CPU Transfer Rates
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-bandwidth-latency-and-compute" class="md-nav__link">
    <span class="md-ellipsis">
      2. Bandwidth, Latency, and Compute
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. Bandwidth, Latency, and Compute">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-bandwidth" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 Bandwidth
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-latency" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 Latency
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23-compute" class="md-nav__link">
    <span class="md-ellipsis">
      2.3 Compute
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#24-compute-vs-memory-bound-regimes" class="md-nav__link">
    <span class="md-ellipsis">
      2.4 Compute vs Memory Bound Regimes
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-training-considerations-for-a-7b-model-on-a-single-a100" class="md-nav__link">
    <span class="md-ellipsis">
      3. Training Considerations for a 7B Model on a Single A100
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Training Considerations for a 7B Model on a Single A100">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-memory-components-during-training" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 Memory Components During Training
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.1 Memory Components During Training">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameter-definitions" class="md-nav__link">
    <span class="md-ellipsis">
      Parameter Definitions
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#311-model-weights" class="md-nav__link">
    <span class="md-ellipsis">
      3.1.1 Model Weights
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#312-gradients" class="md-nav__link">
    <span class="md-ellipsis">
      3.1.2 Gradients
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#313-optimizer-states-adam-or-adamw" class="md-nav__link">
    <span class="md-ellipsis">
      3.1.3 Optimizer States (Adam or AdamW)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#314-activations" class="md-nav__link">
    <span class="md-ellipsis">
      3.1.4 Activations
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#315-total-training-memory" class="md-nav__link">
    <span class="md-ellipsis">
      3.1.5 Total Training Memory
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-techniques-that-enable-feasible-training" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 Techniques That Enable Feasible Training
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-cpu-offloading" class="md-nav__link">
    <span class="md-ellipsis">
      3.3 CPU Offloading
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-memory-differences-between-training-and-inference" class="md-nav__link">
    <span class="md-ellipsis">
      4. Memory Differences Between Training and Inference
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. Memory Differences Between Training and Inference">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41-training-memory-profile" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 Training Memory Profile
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42-inference-memory-profile" class="md-nav__link">
    <span class="md-ellipsis">
      4.2 Inference Memory Profile
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#43-quantitative-difference" class="md-nav__link">
    <span class="md-ellipsis">
      4.3 Quantitative Difference
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-kv-cache-memory-usage" class="md-nav__link">
    <span class="md-ellipsis">
      5. KV Cache Memory Usage
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5. KV Cache Memory Usage">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#51-what-is-the-kv-cache" class="md-nav__link">
    <span class="md-ellipsis">
      5.1 What Is the KV Cache
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#52-which-memory-does-kv-cache-use" class="md-nav__link">
    <span class="md-ellipsis">
      5.2 Which Memory Does KV Cache Use
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#53-kv-cache-memory-scaling" class="md-nav__link">
    <span class="md-ellipsis">
      5.3 KV Cache Memory Scaling
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-summary" class="md-nav__link">
    <span class="md-ellipsis">
      6. Summary
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


  <h1>Memory Consideration</h1>

<h2 id="1-gpu-and-cpu-memory-and-transfer-rates">1. GPU and CPU Memory and Transfer Rates<a class="headerlink" href="#1-gpu-and-cpu-memory-and-transfer-rates" title="Permanent link">&para;</a></h2>
<h3 id="11-gpu-memory">1.1 GPU Memory<a class="headerlink" href="#11-gpu-memory" title="Permanent link">&para;</a></h3>
<p>GPU memory, often called HBM (High Bandwidth Memory) or VRAM, is high bandwidth memory physically attached to the GPU package. It is designed to feed thousands of parallel compute cores efficiently.</p>
<p>Key characteristics:</p>
<ul>
<li>Very high bandwidth</li>
<li>Low access latency relative to CPU memory</li>
<li>Limited capacity compared to system RAM</li>
</ul>
<p>Typical values for NVIDIA A100:</p>
<ul>
<li>Capacity: 40GB or 80GB HBM2e</li>
<li>Peak bandwidth: ~1.6 TB/s</li>
</ul>
<p>GPU memory stores:</p>
<ul>
<li>Model weights</li>
<li>Activations</li>
<li>Gradients</li>
<li>Optimizer states</li>
<li>KV cache during inference and decoding</li>
</ul>
<hr />
<h3 id="12-cpu-memory">1.2 CPU Memory<a class="headerlink" href="#12-cpu-memory" title="Permanent link">&para;</a></h3>
<p>CPU memory refers to system RAM, typically DDR4 or DDR5, located on the motherboard.</p>
<p>Key characteristics:</p>
<ul>
<li>Much larger capacity</li>
<li>Significantly lower bandwidth</li>
<li>Higher latency compared to GPU memory</li>
</ul>
<p>Typical values:</p>
<ul>
<li>Capacity: 64GB to 1TB+</li>
<li>Bandwidth: ~50 to 100 GB/s per socket</li>
</ul>
<p>CPU memory is commonly used for:</p>
<ul>
<li>Data loading and preprocessing</li>
<li>Checkpoint storage before transfer</li>
<li>Offloaded parameters or optimizer states in memory constrained setups</li>
</ul>
<hr />
<h3 id="13-gpu-to-cpu-transfer-rates">1.3 GPU to CPU Transfer Rates<a class="headerlink" href="#13-gpu-to-cpu-transfer-rates" title="Permanent link">&para;</a></h3>
<p>Data movement between GPU and CPU happens over interconnects.</p>
<p>Approximate peak transfer rates:</p>
<ul>
<li>PCIe Gen4: ~32 GB/s</li>
<li>PCIe Gen5: ~64 GB/s</li>
<li>NVLink (A100): ~300 GB/s</li>
</ul>
<p>Even with NVLink, transfer bandwidth is far lower than on-device GPU memory bandwidth, making frequent transfers expensive.</p>
<hr />
<hr />
<h2 id="2-bandwidth-latency-and-compute">2. Bandwidth, Latency, and Compute<a class="headerlink" href="#2-bandwidth-latency-and-compute" title="Permanent link">&para;</a></h2>
<h3 id="21-bandwidth">2.1 Bandwidth<a class="headerlink" href="#21-bandwidth" title="Permanent link">&para;</a></h3>
<p>Bandwidth measures how much data can be transferred per unit time, typically in GB/s or TB/s.</p>
<p>In training and inference:</p>
<ul>
<li>Large tensors are streamed repeatedly</li>
<li>Sustained bandwidth determines throughput</li>
<li>Many transformer operations are memory bandwidth bound</li>
</ul>
<hr />
<h3 id="22-latency">2.2 Latency<a class="headerlink" href="#22-latency" title="Permanent link">&para;</a></h3>
<p>Latency is the delay to access the first byte of data.</p>
<ul>
<li>GPU memory latency is lower than CPU memory</li>
<li>PCIe transfers have high latency relative to on-device access</li>
</ul>
<p>Latency matters for:</p>
<ul>
<li>Small tensor operations</li>
<li>Kernel launch overhead</li>
<li>Synchronization points</li>
</ul>
<p>For large matrix operations, bandwidth dominates over latency.</p>
<hr />
<h3 id="23-compute">2.3 Compute<a class="headerlink" href="#23-compute" title="Permanent link">&para;</a></h3>
<p>Compute refers to the raw arithmetic capability of the processor, measured in FLOPs.</p>
<p>A100 peak performance:
- FP16 or BF16 Tensor Core: ~312 TFLOPs</p>
<p>In practice:
- Many LLM workloads are not compute bound
- Compute units often wait on memory due to limited data reuse</p>
<hr />
<h3 id="24-compute-vs-memory-bound-regimes">2.4 Compute vs Memory Bound Regimes<a class="headerlink" href="#24-compute-vs-memory-bound-regimes" title="Permanent link">&para;</a></h3>
<ul>
<li>Compute bound: performance limited by FLOPs</li>
<li>Memory bound: performance limited by data movement</li>
</ul>
<p>Transformers often become memory bound during:</p>
<ul>
<li>Attention</li>
<li>Layer normalization</li>
<li>Optimizer updates during training</li>
</ul>
<hr />
<hr />
<h2 id="3-training-considerations-for-a-7b-model-on-a-single-a100">3. Training Considerations for a 7B Model on a Single A100<a class="headerlink" href="#3-training-considerations-for-a-7b-model-on-a-single-a100" title="Permanent link">&para;</a></h2>
<h3 id="31-memory-components-during-training">3.1 Memory Components During Training<a class="headerlink" href="#31-memory-components-during-training" title="Permanent link">&para;</a></h3>
<p>Training requires storing four major components in GPU memory:</p>
<ol>
<li>Model weights</li>
<li>Gradients</li>
<li>Optimizer states</li>
<li>Activations</li>
</ol>
<p>We quantify each component explicitly.</p>
<h4 id="parameter-definitions">Parameter Definitions<a class="headerlink" href="#parameter-definitions" title="Permanent link">&para;</a></h4>
<p>Let:</p>
<ul>
<li><span class="arithmatex">\(P = 7 \times 10^9\)</span> parameters  </li>
<li>BF16 precision for weights and gradients: 2 bytes  </li>
<li>FP32 precision for optimizer states: 4 bytes  </li>
</ul>
<hr />
<h4 id="311-model-weights">3.1.1 Model Weights<a class="headerlink" href="#311-model-weights" title="Permanent link">&para;</a></h4>
<div class="arithmatex">\[
M_{\text{weights}} = P \times 2 \text{ bytes}
\]</div>
<div class="arithmatex">\[
= 7 \times 10^9 \times 2 = 14 \text{ GB}
\]</div>
<hr />
<h4 id="312-gradients">3.1.2 Gradients<a class="headerlink" href="#312-gradients" title="Permanent link">&para;</a></h4>
<p>Each trainable parameter produces one gradient tensor.</p>
<div class="arithmatex">\[
M_{\text{grads}} = P \times 2 \text{ bytes}
\]</div>
<div class="arithmatex">\[
= 14 \text{ GB}
\]</div>
<p>Running total so far:</p>
<div class="arithmatex">\[
28 \text{ GB}
\]</div>
<hr />
<h4 id="313-optimizer-states-adam-or-adamw">3.1.3 Optimizer States (Adam or AdamW)<a class="headerlink" href="#313-optimizer-states-adam-or-adamw" title="Permanent link">&para;</a></h4>
<p>Adam maintains two FP32 states per parameter:</p>
<ul>
<li>First moment</li>
<li>Second moment</li>
</ul>
<div class="arithmatex">\[
M_{\text{optimizer}} = P \times 2 \times 4 \text{ bytes}
\]</div>
<div class="arithmatex">\[
= 7 \times 10^9 \times 8 = 56 \text{ GB}
\]</div>
<p>Running total:</p>
<div class="arithmatex">\[
14 + 14 + 56 = 84 \text{ GB}
\]</div>
<p>This already exceeds the memory of an A100 80GB.</p>
<hr />
<h4 id="314-activations">3.1.4 Activations<a class="headerlink" href="#314-activations" title="Permanent link">&para;</a></h4>
<p>Activation memory depends on:</p>
<ul>
<li>Number of layers <span class="arithmatex">\(L\)</span></li>
<li>Batch size <span class="arithmatex">\(B\)</span></li>
<li>Sequence length <span class="arithmatex">\(T\)</span></li>
<li>Hidden dimension <span class="arithmatex">\(H\)</span></li>
</ul>
<p>A simplified scaling relation:</p>
<div class="arithmatex">\[
M_{\text{act}} = O(L \times B \times T \times H \times 2 \text{ bytes})
\]</div>
<p>For a 7B transformer with gradient checkpointing:</p>
<ul>
<li>Activations typically consume 5 to 15 GB</li>
</ul>
<hr />
<h4 id="315-total-training-memory">3.1.5 Total Training Memory<a class="headerlink" href="#315-total-training-memory" title="Permanent link">&para;</a></h4>
<div class="arithmatex">\[
M_{\text{total}} = M_{\text{weights}} + M_{\text{grads}} + M_{\text{optimizer}} + M_{\text{act}}
\]</div>
<div class="arithmatex">\[
\approx 90 \text{ to } 100 \text{ GB}
\]</div>
<p>This explains why full fine-tuning of a 7B model does not fit on a single A100.</p>
<hr />
<h3 id="32-techniques-that-enable-feasible-training">3.2 Techniques That Enable Feasible Training<a class="headerlink" href="#32-techniques-that-enable-feasible-training" title="Permanent link">&para;</a></h3>
<p>Common strategies include:</p>
<ul>
<li>Parameter-efficient fine-tuning such as LoRA or adapters</li>
<li>Mixed precision training using BF16</li>
<li>Gradient checkpointing to reduce activation memory</li>
<li>Small micro-batches with gradient accumulation</li>
<li>Limiting sequence length</li>
</ul>
<p>These techniques primarily reduce:</p>
<ul>
<li>Gradient memory</li>
<li>Optimizer state memory</li>
<li>Activation memory</li>
</ul>
<hr />
<h3 id="33-cpu-offloading">3.3 CPU Offloading<a class="headerlink" href="#33-cpu-offloading" title="Permanent link">&para;</a></h3>
<p>CPU offloading can move:</p>
<ul>
<li>Optimizer states</li>
<li>Parameters</li>
</ul>
<p>Tradeoffs:</p>
<ul>
<li>Enables fitting larger models</li>
<li>Severely reduces training throughput</li>
<li>Often impractical for production training</li>
</ul>
<hr />
<hr />
<h2 id="4-memory-differences-between-training-and-inference">4. Memory Differences Between Training and Inference<a class="headerlink" href="#4-memory-differences-between-training-and-inference" title="Permanent link">&para;</a></h2>
<h3 id="41-training-memory-profile">4.1 Training Memory Profile<a class="headerlink" href="#41-training-memory-profile" title="Permanent link">&para;</a></h3>
<p>Training requires:</p>
<ul>
<li>Weights</li>
<li>Activations from forward pass</li>
<li>Gradients from backward pass</li>
<li>Optimizer states</li>
</ul>
<p>Memory usage is dominated by optimizer states and activations.</p>
<hr />
<h3 id="42-inference-memory-profile">4.2 Inference Memory Profile<a class="headerlink" href="#42-inference-memory-profile" title="Permanent link">&para;</a></h3>
<p>Inference requires:</p>
<ul>
<li>Model weights</li>
<li>Activations for current forward pass</li>
<li>KV cache for attention</li>
</ul>
<p>Notably absent:</p>
<ul>
<li>Gradients</li>
<li>Optimizer states</li>
</ul>
<p>This is why inference fits models that training cannot.</p>
<hr />
<h3 id="43-quantitative-difference">4.3 Quantitative Difference<a class="headerlink" href="#43-quantitative-difference" title="Permanent link">&para;</a></h3>
<p>For a 7B model:</p>
<ul>
<li>Training memory: ~90GB or more</li>
<li>Inference memory: ~20 to 30GB depending on sequence length and KV cache size</li>
</ul>
<hr />
<hr />
<h2 id="5-kv-cache-memory-usage">5. KV Cache Memory Usage<a class="headerlink" href="#5-kv-cache-memory-usage" title="Permanent link">&para;</a></h2>
<h3 id="51-what-is-the-kv-cache">5.1 What Is the KV Cache<a class="headerlink" href="#51-what-is-the-kv-cache" title="Permanent link">&para;</a></h3>
<p>The KV cache stores the key and value tensors from the attention mechanism for previously processed tokens.</p>
<p>It avoids recomputing attention over the full context during autoregressive decoding.</p>
<hr />
<h3 id="52-which-memory-does-kv-cache-use">5.2 Which Memory Does KV Cache Use<a class="headerlink" href="#52-which-memory-does-kv-cache-use" title="Permanent link">&para;</a></h3>
<p>KV cache resides in:</p>
<ul>
<li>GPU memory during standard inference and serving</li>
<li>CPU memory only in specialized offloading or paging setups</li>
</ul>
<p>During high throughput inference:</p>
<ul>
<li>KV cache must stay in GPU memory</li>
<li>Frequent access makes CPU storage impractical</li>
</ul>
<hr />
<h3 id="53-kv-cache-memory-scaling">5.3 KV Cache Memory Scaling<a class="headerlink" href="#53-kv-cache-memory-scaling" title="Permanent link">&para;</a></h3>
<p>KV cache memory scales with:</p>
<ul>
<li>Number of layers</li>
<li>Number of attention heads</li>
<li>Sequence length</li>
<li>Batch size</li>
</ul>
<p>This makes KV cache the dominant memory consumer during long context inference.</p>
<hr />
<hr />
<h2 id="6-summary">6. Summary<a class="headerlink" href="#6-summary" title="Permanent link">&para;</a></h2>
<p>Key takeaways:
- GPU memory is the primary constraint for both training and inference
- Bandwidth often limits performance more than compute
- Training requires additional memory for gradients and optimizer states
- Inference is cheaper because it avoids optimizer and gradient storage
- KV cache lives in GPU memory and dominates long-context inference memory</p>
<p>Understanding these tradeoffs is essential for designing and debugging large-scale LLM systems.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.expand", "navigation.top", "search.highlight", "search.share", "content.code.copy", "mathjax"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>