- Hu, E. J., et al. *LoRA: Low-Rank Adaptation of Large Language Models.* [arXiv:2106.09685](https://arxiv.org/abs/2106.09685)  
- Dettmers, T., et al. *QLoRA: Efficient Finetuning of Quantized LLMs.* [arXiv:2305.14314](https://arxiv.org/abs/2305.14314)  
- **Hugging Face PEFT documentation:** [https://huggingface.co/docs/peft](https://huggingface.co/docs/peft)  
- Community writeups and practical tips (e.g., blog posts and notebooks on LoRA/QLoRA setups).
- "4-bit NormalFloat (NF4) Quantization" – EmergentMind. [Link](https://www.emergentmind.com/topics/4-bit-normalfloat-nf4-quantization)  
1. Dettmers et al., *QLoRA: Efficient Finetuning of Quantized LLMs* (2023)
2. Tim Dettmers, *bitsandbytes* GitHub: [https://github.com/TimDettmers/bitsandbytes](https://github.com/TimDettmers/bitsandbytes)
3. Hugging Face PEFT Documentation: [https://huggingface.co/docs/peft](https://huggingface.co/docs/peft)
4. Manal Elaidouni, *4-Bit Quantization in QLoRA Explained*
5. D. Prasad, *QLoRA Explained – A Deep Dive into Parameter Efficient Fine-Tuning*

* **Paper:** [QLoRA: Efficient Finetuning of Quantized LLMs (Dettmers et al., 2023)](https://arxiv.org/abs/2305.14314)
* **Hugging Face PEFT:** [https://huggingface.co/docs/peft](https://huggingface.co/docs/peft)
* **Bitsandbytes Library:** [https://github.com/TimDettmers/bitsandbytes](https://github.com/TimDettmers/bitsandbytes)
